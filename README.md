# Azure Speech Translation Avatar

Real-time speech translation with AI avatar synthesis. A speaker talks in one language, and listeners see an AI avatar speak the translation in their chosen language.

> **Status**: âœ… Local deployment tested | â³ Cloud deployment testing pending

## Features

| Feature | Description |
|---------|-------------|
| ðŸŽ¤ **Real-time Translation** | Continuous speech recognition with live translation |
| ðŸ¤– **AI Avatar** | Azure Avatar synthesizes translated speech with lip-sync |
| ðŸ‘¥ **Speaker/Listener Mode** | Separate interfaces for presenter and audience |
| ðŸ“¡ **WebRTC Streaming** | Low-latency avatar video via WebRTC |
| ðŸ”„ **Real-time Broadcasting** | All listeners receive translations simultaneously via Socket.IO |
| ðŸŒ **Language Support** | https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=speech-translation |

## Quick Start

### Prerequisites

- Python 3.8+
- Azure Speech Service
- Speech to Text Avatar and Custom Avatar https://learn.microsoft.com/en-us/azure/ai-services/speech-service/text-to-speech-avatar/what-is-text-to-speech-avatar
- Modern browser (Chrome, Edge, Firefox)

### Installation

```powershell
# 1. Install dependencies
pip install -r requirements.txt

# 2. Configure Azure credentials
cp .env.example .env
# Edit .env with your SPEECH_REGION and SPEECH_KEY

# 3. Run the application
python -m flask run --host=0.0.0.0 --port=5000
```

### Usage

1. **Speaker** opens `http://localhost:5000/speaker`
2. Configure session (name, source language, target language, avatar)
3. Click **Create Session** â†’ Copy the listener URL
4. **Listeners** open the listener URL in their browsers
5. **Wait** for the avatar to connect (video appears in listener window)
6. Speaker clicks **Start Speaking** â†’ All listeners see the avatar + translations

> ðŸ“‹ **Demo Sequence**: Always wait for the listener's avatar to fully connect before the speaker starts talking. The avatar connection takes a few seconds â€” you'll see the video feed appear when ready.

> âš ï¸ **Demo Tip**: Avoid running speaker and listener on the same device â€” the microphone will pick up the avatar's audio output, causing feedback loops. Use **Dev Tunnels** to share the listener URL and open it on a separate device (phone, tablet, or another computer) for the best demo experience.

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SPEAKER         â”‚     â”‚   FLASK SERVER  â”‚     â”‚  LISTENER(S)     â”‚
â”‚  speaker.html    â”‚     â”‚    app.py       â”‚     â”‚  listener.html   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Create session â”‚â”€â”€â”€â”€>â”‚ â€¢ Session mgmt  â”‚     â”‚ â€¢ Avatar video   â”‚
â”‚ â€¢ Start/stop     â”‚     â”‚ â€¢ Translation   â”‚â”€â”€â”€â”€>â”‚ â€¢ Live captions  â”‚
â”‚ â€¢ See captions   â”‚<â”€â”€â”€â”€â”‚ â€¢ Broadcasting  â”‚     â”‚ â€¢ History        â”‚
â”‚ (No avatar)      â”‚     â”‚ â€¢ WebRTC relay  â”‚     â”‚ (No controls)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Speaker** controls translation; **Listeners** see/hear the avatar. Translation results are broadcast to all listeners via Socket.IO, while each listener has their own WebRTC connection to Azure Avatar Service.

## Configuration

### Environment Variables

Create a `.env` file with your Azure credentials:

```env
# Required
SPEECH_REGION=
SPEECH_KEY=your_speech_service_key

# Optional
PORT=5000
ICE_SERVER_URL=           # Custom TURN server
ICE_SERVER_USERNAME=
ICE_SERVER_PASSWORD=
```

### Supported Languages

https://learn.microsoft.com/en-us/azure/ai-services/speech-service/text-to-speech-avatar/what-is-text-to-speech-avatar

Custom avatars trained in Azure Speech Studio are also supported.

## API Reference

### Routes

| Route | Method | Description |
|-------|--------|-------------|
| `/speaker` | GET | Speaker control interface |
| `/listener/<session_id>` | GET | Listener interface with avatar |
| `/api/createSession` | POST | Create translation session |
| `/api/getSession/<id>` | GET | Get session information |
| `/api/startTranslation` | POST | Start translation (speaker) |
| `/api/stopTranslation` | POST | Stop translation |
| `/api/endSession` | POST | End session and notify listeners |
| `/api/connectListenerAvatar` | POST | Connect listener to avatar (WebRTC) |
| `/api/getIceToken` | GET | Get ICE/TURN credentials |

### Socket.IO Events

| Event | Direction | Description |
|-------|-----------|-------------|
| `joinSession` | Client â†’ Server | Listener joins session room |
| `translationResult` | Server â†’ Clients | Broadcast translation to session |
| `listenerJoined` | Server â†’ Speaker | New listener notification |
| `listenerCountUpdated` | Server â†’ All | Updated listener count |
| `sessionEnded` | Server â†’ Listeners | Session terminated |
| `audioData` | Speaker â†’ Server | Browser audio streaming (16kHz PCM) |

## Remote Access

### Option 1: VS Code Dev Tunnels (Recommended)

```
1. Open PORTS tab in VS Code
2. Forward port 5000
3. Set visibility to "Public"
4. Share the tunnel URL with listeners
```

### Option 2: ngrok

```powershell
ngrok http 5000
# Share the https URL
```

> **Note**: HTTPS is required for microphone access in browsers.

## Deployment

### Docker

```powershell
# Build
docker build -t speech-avatar .

# Run
docker run -p 5000:5000 --env-file .env speech-avatar
```

### Azure App Service

```powershell
.\scripts\deploy-azure-app-service.ps1 -ResourceGroupName "my-rg" -AppServiceName "my-app"
```

See [docs/3-SETUP-AZURE.md](docs/3-SETUP-AZURE.md) for detailed deployment options.

## Troubleshooting

| Issue | Solution |
|-------|----------|
| Avatar not connecting | Verify SPEECH_KEY and SPEECH_REGION in .env |
| No microphone input | HTTPS required for mic access (use Dev Tunnels) |
| Listeners not receiving translations | Check Socket.IO connection in browser console |
| WebRTC failed | Check firewall isn't blocking TURN traffic |

## Documentation

| Document | Description |
|----------|-------------|
| [1-ARCHITECTURE.md](docs/1-ARCHITECTURE.md) | System architecture and data flows |
| [2-SETUP-LOCAL.md](docs/2-SETUP-LOCAL.md) | Local development setup |
| [3-SETUP-AZURE.md](docs/3-SETUP-AZURE.md) | Azure deployment guide |
| [4-IMPLEMENTATION.md](docs/4-IMPLEMENTATION.md) | Code implementation details |
| [5-TESTING.md](docs/5-TESTING.md) | Testing scenarios and checklist |

## Project Structure

```
avatar-translation/
â”œâ”€â”€ app.py                 # Flask server with Socket.IO
â”œâ”€â”€ speaker.html           # Speaker control interface
â”œâ”€â”€ listener.html          # Listener avatar interface
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/styles.css     # Shared styles
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ speaker.js     # Speaker client logic
â”‚       â””â”€â”€ listener.js    # Listener client logic (WebRTC)
â”œâ”€â”€ scripts/               # Deployment and utility scripts
â”‚   â”œâ”€â”€ start.ps1          # Quick start script
â”‚   â”œâ”€â”€ deploy-docker.ps1  # Docker deployment
â”‚   â””â”€â”€ deploy-azure-app-service.ps1  # Azure deployment
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ .env.example           # Environment template
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ Dockerfile             # Container build
```

## Technology Stack

- **Backend**: Flask + Flask-SocketIO + Eventlet
- **Frontend**: Vanilla JS + Socket.IO client
- **Streaming**: WebRTC for avatar video, Socket.IO for translations
- **Azure Services**: Speech Translation, Speech Synthesis, Avatar Synthesis

## License

Copyright (c) Microsoft Corporation. Licensed under the MIT license.
